#!/home/sam/anaconda3/bin/python

########################################
# IMPORTS
########################################
import matplotlib.pyplot as plt
import numpy as np, os, sys
import argparse
from astropy.io import fits 
from astropy.visualization import simple_norm
import pkg_resources
from scipy.signal import find_peaks
from tqdm import tqdm 
from multiprocess import Pool
import matplotlib.patches as patches
from astropy.table import Table, Column, Row
#plt.style.use('dark_background')
from lmfit import Parameters, fit_report, minimize
# My own imports
from spec1d.create_log import create_log # This function re-creates a log file for a night based on the fits files there
from spec1d.image_tracing import trace_image_between_rows, trace_image_between_cols, trace_image_between_lines, find_science_image_bounds , plot_rectangle, trace_rectangle # These functions handle the summing of flux
from spec1d.lmfit_funcs import fit_box_to_step_function, fit_box_to_step_function_science, fit_gaussians_to_emission_lines
from spec1d.align_distorted_spectra import align_distorted_spectra, spready
from spec1d.align_O2 import align_with_O2

import glob
from astroscrappy import detect_cosmics 

from scipy.stats import median_absolute_deviation
from scipy.ndimage import median_filter
from astropy.coordinates import SkyCoord
import astropy.units as u
from scipy.signal import correlate
from barycorrpy import get_BC_vel # with barrcorpy you need astropy 4.0 as the time calls change
from astropy.time import Time 

########################################
# Argumant parser
########################################
description = '''Spupnic reduction code'''


parser = argparse.ArgumentParser('spupnic', description=description)

parser.add_argument('--create_log', action="store_true", default=False, help="Create the log file")

parser.add_argument('-b', 
                    '--extract_science',
                     help='Extract science spectra from a log file', type=str, default='no')

parser.add_argument('-d', 
                    '--threads',
                     help='The number of threads to use.', type=int , default=12)

parser.add_argument('-e', 
                    '--grating',
                     help='The grating (overides from header).', type=str, default = 'None')

parser.add_argument('-f', 
                    '--gratingangle',
                     help='The grating angle (overides from header).', type=str, default = '-99')

parser.add_argument('-g', 
                    '--verbose',
                     help='Full verbose', type=bool, default = False)


parser.add_argument('-i', 
                    '--skyflux_sigma',
                     help='The sigma for which to clip cosmic rays', type=float, default = 5.)

parser.add_argument('-j', 
                    '--stellarflux_sigma',
                     help='The sigma for which to clip cosmic rays', type=float, default = 3.)

parser.add_argument('--extract_all_science', action="store_true", default=False, help="Extract all science spectra")
parser.add_argument('--process_folder', action="store_true", default=False, help="Process entire night of data.")
parser.add_argument('--reject_cosmics', action="store_true", default=False, help="Process entire night of data.")
parser.add_argument('--purge', action="store_true", default=False, help="Process entire night of data.")
parser.add_argument('--list_science', action="store_true", default=False, help="Process entire night of data.")
parser.add_argument('--O2_tweak', action="store_true", default=False, help="Process entire night of data.")



########################################
# Worker functions
########################################

def extract_all_science_worker(i):
    cmd = 'spupnic --extract_science {:} --grating {:} --gratingangle {:}'.format(t['FILE'][i], args.grating, args.gratingangle)
    if args.reject_cosmics : cmd += ' --reject_cosmics'
    if args.O2_tweak : cmd += ' --O2_tweak'

    try : os.system(cmd)
    except : pass 



def make_reference_spectra_with_gui(x, traced_flux, traced_flux_peaks, grating, gratingangle):
    plt.close()

    fig = plt.figure(figsize=(10,5))
    ax = fig.add_subplot(111)
    ax.set(title = 'lamp line picker', xlabel='Pixel', ylabel='Flux')
    bbox = dict(boxstyle="round", fc="0.8")
    arrowprops = dict(
        arrowstyle = "->",
        connectionstyle = "angle,angleA=0,angleB=90,rad=10")


    _, = ax.plot(x, traced_flux, c='k')
    line, = ax.plot(x[traced_flux_peaks], traced_flux[traced_flux_peaks], 'ro', markersize = 20, picker=1)  # 5 points tolerance
    wavelengths = np.zeros(len(traced_flux_peaks))
    ax.invert_xaxis()

    def onpick(event):
        thisline = event.artist
        xdata = thisline.get_xdata()
        ydata = thisline.get_ydata()
        ind = event.ind
        points = tuple(zip(xdata[ind], ydata[ind]))[0]
        wavelength = float(input('Enter the wavelength of this peak [nm] : '))
        wavelengths[np.where(x[traced_flux_peaks]==points[0])[0][0]] = wavelength 
        
        s = '{:.3f} nm'.format(wavelength)
        xytext = (points[0] + 30, points[1] + 0.1)
        ax.annotate(s, xy=points, xytext=xytext, bbox=bbox, arrowprops=arrowprops)
        plt.draw()
    fig.canvas.mpl_connect('pick_event', onpick)
    plt.show(block=True)

    return x[traced_flux_peaks][wavelengths!=0], wavelengths[wavelengths!=0]

if __name__=="__main__":
    # First, parse the args 
    args = parser.parse_args()

    # Check for purge 
    if args.purge:
        os.system('rm *.npy *.png log.fits *_spectra.fits')

    # Create the logfile
    if args.create_log : create_log()

    # List science
    if args.list_science:
        t = Table.read('log.fits')
        t = t[t['EXPTYPE']=='SCIENCE'] 

        header = ''
        for i in t.colnames : header += '{:>25}'.format(i)
        print(header)

        for i in range(len(t)) : 
            row = ''
            for j in t.colnames : row += '{:>25}'.format(t[j][i])
            print(row)
        exit()


    if args.extract_science != 'no':
        h = fits.open(args.extract_science)
        if args.reject_cosmics:
            _, xx = detect_cosmics(h[0].data)
            h[0].data = xx
        if args.grating =='None' : grating = h[0].header['GRATING']
        else :                     grating = args.grating
        if args.gratingangle ==-99 : gratingangle = int(str(h[0].header['GR-ANGLE']).split('.')[0])
        else :                     gratingangle = args.gratingangle

        norm = simple_norm(h[0].data, 'sqrt', min_percent=5, max_percent=95)

        f1 = plt.figure()
        ax1 = plt.gca()
        ax1.imshow(h[0].data, aspect='auto', norm=norm, origin='lower', cmap = 'Greys')
        ax1.set(title = '{:} [grating {:} Angle {:}]'.format(args.extract_science, grating, gratingangle),
                xlabel='X', ylabel='Y')
        ax1.axhline(40, c='r', alpha = 0.3, ls = '--')
        ax1.axhline(100, c='r', alpha = 0.3, ls = '--')
        plt.close()

        # Now find ThAr within specified time limit
        t = Table.read('log.fits') 
        time_of_obs = t['HJD'][np.where(t['FILE']==args.extract_science)[0][0]]
        arc_table = t[(t['EXPTYPE']=='ARC')]
        arc_table = arc_table[np.abs(arc_table['HJD'] - time_of_obs) < 1/24] 
        if len(arc_table) == 0 : 
            #raise ValueError('No arc calibrations within 1 hr')
            print('No arcs within 1 hour of obs :(, using all')
            exit()

        # Create the figure
        fig1 = plt.figure(constrained_layout=True, figsize = (18,10))
        gs = fig1.add_gridspec(4, 3)
        axs = np.array([[fig1.add_subplot(gs[0, 0]), fig1.add_subplot(gs[0, 1]), fig1.add_subplot(gs[0, 2])],   
                        [fig1.add_subplot(gs[1, :]), fig1.add_subplot(gs[2, :]), fig1.add_subplot(gs[3, :])]],dtype=object)


        
        # Now load and trace the science image
        # Now we move on to the science image 
        h = fits.open(args.extract_science)
        if args.reject_cosmics:
            _, xx = detect_cosmics(h[0].data)
            h[0].data = xx
        norm = simple_norm(h[0].data, 'sqrt', min_percent=5, max_percent=95)
        axs[0][1].imshow(h[0].data, aspect='auto', norm=norm, origin='lower', cmap = 'Greys')
        axs[0][1].axhline(40, c='r', alpha = 0.3, ls = '--')
        axs[0][1].axhline(100, c='r', alpha = 0.3, ls = '--')
        axs[0][1].set(xlabel='X', ylabel='Y', title = '{:} [grating {:} Angle {:}]'.format(args.extract_science, grating, gratingangle))
        

        # Now we will trace the spectra
        # to do this, we will select 5 in x
        regions = np.array([[100,150], [500,550], [1000,1050], [1450, 1550], [1750, 1800] ])
        bounds, slit_width = [], []
        for region in regions : 
            bounds_ = find_science_image_bounds(1e-4, 100, 50,   h[0].data[:,region[0]:region[1]], vertical_oversample=10, horizontal_oversample=10)[0] 
            x = np.array([region[0], region[1], region[1], region[0]])
            y = np.array([bounds_[0], bounds_[0], bounds_[1], bounds_[1]])
            plot_rectangle(x, y, axs[0][1], c='g')
            bounds.append(bounds_)
            slit_width.append(0.75*(np.max(y) - np.min(y)))
        slit_width = np.median(slit_width)
        bounds = np.array(bounds)
        slit_gradient = np.polyfit(np.mean(regions, axis=1), bounds.T[1], 1)[0]
        print('Slit gradient determined to be {:}'.format(slit_gradient))
        print('SW' , slit_width)

        x1, x2 = 35, 1970
        y1, low = find_science_image_bounds(slit_gradient, 100,50,   h[0].data[:,x1:(x1+30)], vertical_oversample=10, horizontal_oversample=10)[0]
        y2 = y1 + slit_gradient*(x2-x1)

        dx = slit_width / (1 + (1 / slit_gradient) )
        dy = slit_width / (1 + slit_gradient) 
        x3 = x2 + dx 
        y3 = y2 - dy  
        x4 = x1 + dx  
        y4 = y1 - dy

        flux_rectangle = np.array([[x1,x2,x3,x4],[y1,y2,y3,y4]])
        sky_lower_rectangle = np.copy(flux_rectangle)
        dx = -2*slit_width / (1 + (1 / slit_gradient) )
        dy = -2*slit_width / (1 + slit_gradient) 
        sky_lower_rectangle[0] = sky_lower_rectangle[0] - dx
        sky_lower_rectangle[1] = sky_lower_rectangle[1] + dy

        sky_upper_rectangle = np.copy(flux_rectangle)
        dx = 2*slit_width / (1 + (1 / slit_gradient) )
        dy = 2*slit_width / (1 + slit_gradient) 
        sky_upper_rectangle[0] = sky_upper_rectangle[0] - dx
        sky_upper_rectangle[1] = sky_upper_rectangle[1] + dy


        plot_rectangle(*flux_rectangle, axs[0][1], c='r')
        plot_rectangle(*sky_lower_rectangle, axs[0][1], c='g')
        plot_rectangle(*sky_upper_rectangle, axs[0][1], c='g')

        x, stellar_flux = trace_rectangle(h[0].data, *flux_rectangle, upsamplex=5, upsampley=5, ax = None) 
        _, sky_lower_flux = trace_rectangle(h[0].data, *sky_lower_rectangle, upsamplex=5, upsampley=5, ax = None) 
        _, sky_upper_flux = trace_rectangle(h[0].data, *sky_upper_rectangle, upsamplex=5, upsampley=5, ax = None) 
        avrg_sky = (sky_lower_flux + sky_upper_flux) / 2.

        axs[1][1].plot(x, stellar_flux - avrg_sky)

        # Ideally, we want to take the average of the one before and the one after.
        # The backup is to use the closest in time
        AVERAGE_WAVECAL = False
        arc_table_before = arc_table[arc_table['HJD'] < time_of_obs]
        arc_table_after= arc_table[arc_table['HJD'] > time_of_obs]
        print('Number of calibrations before {:}'.format(len(arc_table_before)))
        print('Number of calibrations adter  {:}'.format(len(arc_table_after)))

        if (len(arc_table_before)!=0) and (len(arc_table_after) != 0):
            print('Using the average wavelength calibraration for the reference file before and after. ')
            before_filename = '{:}.fits'.format(arc_table_before['FILE'][np.argmax(arc_table_before['HJD'])].split('.')[0])
            after_filename  = '{:}.fits'.format(arc_table_after['FILE'][np.argmin(arc_table_after['HJD'])].split('.')[0])
            reference_spectral_files = [before_filename,after_filename]
            print('\tnearest calibration before : {:}'.format(before_filename))
            print('\tnearest calibration after  : {:}'.format(after_filename))
            AVERAGE_WAVECAL = True
            
        else:
            nearest_filename = '{:}.fits'.format(arc_table['FILE'][np.argmin(arc_table['HJD'] - time_of_obs)].split('.')[0]) 
            print('Using nearest calibration file : {:}'.format(nearest_filename))
            reference_spectral_files = [nearest_filename]


        # Now plot the bounds of the trace
        reference_spectra_pixel_calibrations = []
        calibration_spectra_cards = []
        for i in range(len(reference_spectral_files)):
            # First, plot the calibration image
            h = fits.open(reference_spectral_files[i])
            norm = simple_norm(h[0].data, 'sqrt', min_percent=5, max_percent=95)
            axs[0][i*-1].imshow(h[0].data, aspect='auto', norm=norm, origin='lower', cmap='Greys')
            axs[0][i*-1].axhline(40, c='r', alpha = 0.3, ls = '--')
            axs[0][i*-1].axhline(100, c='r', alpha = 0.3, ls = '--')
            axs[0][i*-1].set(xlabel='X', ylabel='Y', title = '{:} [grating {:} Angle {:}]'.format(reference_spectral_files[i], grating, gratingangle))
            plot_rectangle(*flux_rectangle, axs[0][i*-1], c='r')
 
            # Now trace the true CuNe spectra from the mean gradient and extent of the slit
            x, traced_flux = trace_rectangle(h[0].data, *flux_rectangle, upsamplex=5, upsampley=5, ax = None) 
            traced_flux = traced_flux / traced_flux.max() # normalise and reverse flux
            traced_flux = traced_flux - np.percentile(traced_flux, 20) # remove the 20th percentile to align bottom with 0
            axs[1][i*-1].plot(x, traced_flux, c='k', alpha = 0.4, ls='--', label = 'Traced spectra')

            # Now the problim with calibration is that some peaks are there and some are not. 
            # Lets do a peak find of the traced flux to see what peaks match up with the calibration
            traced_flux_peaks, _ = find_peaks(traced_flux, height = 0.1*np.std(traced_flux), distance = 5) 
            axs[1][i*-1].scatter(x[traced_flux_peaks], traced_flux[traced_flux_peaks], c='y', marker = "2", label='Traced spectra peaks')
 

            # Now we need to load in the reference spectra 
            # that corrosponds to the mask     
            try : 
                ref_spectra = pkg_resources.resource_filename('spec1d', 'data/{:}_{:}_ref_spectra.npy'.format(grating, gratingangle))
                print(ref_spectra)
                ref_spectra = np.load(ref_spectra, allow_pickle=True)
            except : 
                print('No reference loines found for grating {:} [angle {:}]\nAttempting to make one with gui'.format(grating, gratingangle))
                clibration_x, calibration_wavelength = make_reference_spectra_with_gui(x, traced_flux, traced_flux_peaks, grating, gratingangle)
                output_filename = '{:}_{:}_ref_spectra.npy'.format(grating, gratingangle)
                output_data = np.array([x, traced_flux, clibration_x, calibration_wavelength], dtype = object)
                print(output_data)
                np.save(output_filename,output_data)
                print('Saved calibration data to {:}. Please copy this to src/spec1d/data and re-install spec1d.'.format(output_filename))
                exit()


            # Now give the spectra a spready
            spreader = spready(x,traced_flux,ref_spectra[0], ref_spectra[1])
            spreader.fit_spready()
            calibration = np.array([spreader.convert_reference_points_to_spectra(ref_spectra[2]),ref_spectra[3]]).T # the pixel positions of the wavelength calibration
            #preader.plot_solution()

            # Now fit Gaussians at each line to find the best line center - replace the calibrations pixel positions with these positions
            #print('B', calibration[:,0])
            calibration[:,0], aplitudes, sigmas, gauss_model_out = fit_gaussians_to_emission_lines(traced_flux, calibration[:,0], verbose=args.verbose, x=x)
            #print('A', calibration[:,0])
            # now annotate the lamp spectra
            bbox = dict(boxstyle="round", fc="0.8")
            arrowprops = dict(
                arrowstyle = "->",
                connectionstyle = "angle,angleA=0,angleB=90,rad=10")
            for cal in calibration:
                #print('\t{:} -> {:} nm'.format(*cal))
                s = '{:.1f} nm'.format(cal[1])
                xy = (cal[0], np.interp(cal[0], x, traced_flux))
                xytext =  (cal[0]-10, np.interp(cal[0], x, traced_flux)+0.1)
                axs[1][i*-1].annotate(s, xy=xy, xytext=xytext, bbox=bbox, arrowprops=arrowprops)

            # Now append the calibration
            idx_sort = np.argsort(calibration[:,0])
            reference_spectra_pixel_calibrations.append(calibration[idx_sort])
            calibration_spectra_cards.append(fits.ImageHDU(traced_flux))



        # now prep the calibration 
        if len(reference_spectra_pixel_calibrations) > 1:
            print('Averageing 2 calibrations')
            for i in range(reference_spectra_pixel_calibrations[1].shape[0]):
                print('{:} nm    {:}      {:}      [{:}]'.format(reference_spectra_pixel_calibrations[0][i][1],
                                                                 reference_spectra_pixel_calibrations[0][i][0],
                                                                 reference_spectra_pixel_calibrations[1][i][0],
                                                                 reference_spectra_pixel_calibrations[1][i][0] - reference_spectra_pixel_calibrations[0][i][0]))
            reference_spectra_pixel_calibrations =  np.array([(reference_spectra_pixel_calibrations[0][:,0] + reference_spectra_pixel_calibrations[1][:,0]) / 2, reference_spectra_pixel_calibrations[0][:,1]]).T
        else : reference_spectra_pixel_calibrations = reference_spectra_pixel_calibrations[0] 

        # Now we need to interplate x into wavelength using reference_spectra_pixel_calibrations
        wavelength = np.interp(x , reference_spectra_pixel_calibrations[:,0], reference_spectra_pixel_calibrations[:,1], left = -99, right=-99)
        mask = (wavelength!=-99)
        tmp = np.array([wavelength[mask], (stellar_flux - avrg_sky)[mask], np.ones(wavelength.shape[0])[mask]]).T[::-1]

        # Now save
        plt.savefig('{:}_{:}_spectra.png'.format(args.extract_science.split('.')[0], h[0].header['OBJECT']))
        plt.close()

        # Now tweak the wavelength solution using the O2 absorbtion
        if args.O2_tweak:
            # Load the O2 absorbtion
            try : 
                O2_spectra = pkg_resources.resource_filename('spec1d', 'data/{:}_{:}_O2.txt'.format(grating, gratingangle))
                print('Loading O2 from ' + O2_spectra)
                O2_spectra = np.loadtxt(O2_spectra)
            except : 
                print('Unable to load O2 ')
            O2_fig, tmp, O2_RV, O2_RV_err = align_with_O2(tmp, O2_spectra)
            O2_fig.savefig('{:}_{:}_O2_correction.png'.format(args.extract_science.split('.')[0], h[0].header['OBJECT']))
            plt.close()


        # Now write out the spectra
        card = fits.PrimaryHDU(tmp)
        coord = SkyCoord('{:} {:}'.format(h[0].header['TARG-RA'], h[0].header['TARG-DEC']), unit=(u.hourangle, u.deg))
        card.header.set('RA',  float(coord.ra.value) , 'righ asc')
        card.header.set('DEC', float(coord.dec.value) , 'Dec')
        card.header.set('OBJECT', str(h[0].header['OBJECT']) , 'name of object')
        card.header.set('HJD-OBS', float(h[0].header['HJD-OBS']+2400000) , 'HJD of obs')

        BV = get_BC_vel(JDUTC=Time(h[0].header['HJD-OBS']+2400000, format='jd'), ra=coord.ra.value,dec=coord.dec.value, obsname='SAAO')[0][0] / 1e3
        card.header.set('BV', BV , 'Barycentric velocity')

        if args.O2_tweak:
            card.header.set('O2_RV', O2_RV , 'O2 telluric wavelength correction (km/s).')
            card.header.set('O2_RV_err', O2_RV_err , 'O2 telluric wavelength correction err (km/s)')


        science_image_cards = [fits.ImageHDU(x[mask]), 
                               fits.ImageHDU(stellar_flux[mask]),
                               fits.ImageHDU(sky_lower_flux[mask]),
                               fits.ImageHDU(sky_upper_flux[mask]),
                               fits.ImageHDU(avrg_sky[mask])]
            

        fits.HDUList([card, *science_image_cards, *calibration_spectra_cards]).writeto('{:}_{:}_spectra.fits'.format(args.extract_science.split('.')[0], h[0].header['OBJECT']), overwrite=True)





            




    if args.extract_all_science:
        # Load the log file
        t = Table.read('log.fits')

        # now filter all those with Science frames
        t = t[t['EXPTYPE']=='SCIENCE']

        # Now multiprocess
        with Pool(args.threads) as pool:
            pool.map(extract_all_science_worker, range(len(t)))


    if args.process_folder:
        # Get the log file
        os.system('spupnic --create_log')

        # Load the log file
        #t = Table.read('log.fits')
        #t = t[(t['EXPTYPE']=='ARC')] #& (t['ARC-LAMP']=='CuNe')]
        #with Pool(args.threads) as pool:
        #    pool.map(extract_all_CuNe_worker, range(len(t)))

        t = Table.read('log.fits')
        t = t[t['EXPTYPE']=='SCIENCE']
        with Pool(args.threads) as pool:
            pool.map(extract_all_science_worker, range(len(t)))

